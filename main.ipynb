{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32babeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70e8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap\n",
    "    )\n",
    "    return splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3087dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nothing\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nothing\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_chunks(chunks):\n",
    "    return embedder.encode(chunks, convert_to_tensor=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf052faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    dim = embeddings[0].shape[0]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b794742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_chunks(query, chunks, index, embedder, top_k=5):\n",
    "    query_emb = embedder.encode([query])[0]\n",
    "    D, I = index.search(np.array([query_emb]), top_k)\n",
    "    return [chunks[i] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e6f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# AIzaSyA2Umg0zYQAqCIQxyPJYCD5cgZjqpodEZg\n",
    "genai.configure(api_key=\"Your-Gemini_API\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "def generate_answer_with_gemini(query, context):\n",
    "    prompt = f\"\"\"\n",
    "You are a smart assistant. Based on the following document context, answer the question or generate a summary.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Task: {query}\n",
    "\"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980e32a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the document in bullet points:\n",
      "\n",
      "*   **Steps to Create a College ER Diagram:**\n",
      "    *   Change the name of the schema.\n",
      "    *   Use the \"new table tool\" to add tables to the drawing area.\n",
      "    *   Click on each table to rename it and add columns (e.g., `Students` table and its columns).\n",
      "    *   Add relationships between the tables.\n",
      "    *   The document shows a \"Complete ER diagram.\"\n",
      "*   **Converting College ER Diagram to Schema:**\n",
      "    *   Select \"Forward Engineer\" from the \"Database\" tab.\n",
      "*   **College Database Entities (Tables) and Attributes:**\n",
      "    *   `Students`: St_Id, St_name, Phone, Nat_id, Dept_Id\n",
      "    *   `Instructor`: Inst_Id, Inst_name, Phone, Nat_id\n",
      "    *   `Courses`: Crs_id, Crs_name, Crs_description, Inst_Id\n",
      "    *   `Departments`: Dept_Id, Dept_name, Dept_Location\n",
      "    *   `NationalId`: Nat_Id\n",
      "    *   `Stud_Courses`\n",
      "*   **Chapter 5: Join (Database Concepts):**\n",
      "    *   **Chapter Content:** Join, Aggregate Functions, Grouping, Order by.\n",
      "    *   **Join:** Used to retrieve information from more than one table.\n",
      "        *   Example query provided: Retrieving employee and department names based on salary condition, using `JOIN` and `ON` clauses.\n",
      "        *   Another example query provided (with missing `ON` clause): Joining Students, Courses, and Departments tables to retrieve student and course names for a specific department.\n",
      "    *   **Aggregate Functions:**\n",
      "        *   Listed functions: `Sum()`, `Max()`, `Avg()`, `Count()`, `Min()`.\n",
      "        *   Example query: Using `count(*)` to retrieve the number of employees in a specific department.\n"
     ]
    }
   ],
   "source": [
    "# Load PDF\n",
    "text = extract_text_from_pdf(\"Chapter+5+-+Join.pdf\")\n",
    "\n",
    "# Chunking\n",
    "chunks = chunk_text(text)\n",
    "\n",
    "# Embeddings\n",
    "embeddings = embed_chunks(chunks)\n",
    "\n",
    "# Indexing\n",
    "index = create_faiss_index(embeddings)\n",
    "\n",
    "# Ask a question or request a summary\n",
    "query = \"Summarize the document in bullet points\"\n",
    "\n",
    "# Retrieve\n",
    "top_chunks = retrieve_top_chunks(query, chunks, index, embedder)\n",
    "\n",
    "# Generate answer\n",
    "context = \"\\n\\n\".join(top_chunks)\n",
    "output = generate_answer_with_gemini(query, context)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36382ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import google.generativeai as genai\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Read PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "\n",
    "def extract_more_than_one_pdf(pdf_paths):\n",
    "    all_text = \"\"\n",
    "    for path in pdf_paths:\n",
    "        pdf_text = extract_text_from_pdf(path)\n",
    "        if pdf_text:\n",
    "            all_text += f\"\\n\\n### Content from: {path} ###\\n\\n{pdf_text}\\n\"\n",
    "    return all_text\n",
    "\n",
    "# Chunking\n",
    "def split_text(text, chunk_size=500, overlap=100):\n",
    "    return [\n",
    "        text[i:i + chunk_size]\n",
    "        for i in range(0, len(text), chunk_size - overlap)\n",
    "    ]\n",
    "\n",
    "# Main function with relevant chunk selection\n",
    "def ask_pdf_question(pdf_path, question, top_k=5):\n",
    "    genai.configure(api_key=\"Your-Gemini_API\")\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "    if isinstance(pdf_path, list):\n",
    "        pdf_text = extract_more_than_one_pdf(pdf_path)\n",
    "    else:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    chunks = split_text(pdf_text)\n",
    "\n",
    "    # Compute relevance\n",
    "    chunk_embeddings = embedder.encode(chunks, convert_to_tensor=True)\n",
    "    question_embedding = embedder.encode(question, convert_to_tensor=True)\n",
    "\n",
    "    cosine_scores = util.cos_sim(question_embedding, chunk_embeddings)[0]\n",
    "    top_indices = cosine_scores.argsort(descending=True)[:top_k]\n",
    "    top_chunks = [chunks[i] for i in top_indices]\n",
    "\n",
    "    # Build prompt\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = f\"\"\"You are an intelligent assistant. Answer the question strictly based on the document context provided below.\n",
    "\n",
    "Do not use any external knowledge.\n",
    "\n",
    "If the answer is not in the context, respond with \"The answer is not available in the provided document.\"\n",
    "\n",
    "Be concise and clear.\n",
    "\n",
    "Document Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fcb61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join is used in case of retrieving information from more than one table.\n"
     ]
    }
   ],
   "source": [
    "answer = ask_pdf_question(\"Chapter+5+-+Join.pdf\",\"what are Joins ?\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
